{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt-get install ninja-build\n",
    "!ninja --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.path.exists('/content/nvdiffrast'):\n",
    "  !rm -rf /content/nvdiffrast\n",
    "\n",
    "!git clone --recursive https://github.com/NVlabs/nvdiffrast\n",
    "%cd /content/nvdiffrast\n",
    "!pip install .\n",
    "%cd /content/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import nvdiffrast.torch as dr\n",
    "\n",
    "from IPython.display import Image\n",
    "from torchvision.transforms import ToPILImage\n",
    "from torchvision.transforms import RandomPerspective\n",
    "from einops import rearrange, reduce, repeat\n",
    "\n",
    "to_img = ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_opengl = False # On T4 GPU, only False works, but rasterizer works much better if = True\n",
    "glctx = dr.RasterizeGLContext() if use_opengl else dr.RasterizeCudaContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cond_noise_sampling(src_noise, level=3):\n",
    "\n",
    "    B, C, H, W = src_noise.shape\n",
    "\n",
    "    up_factor = 2 ** level\n",
    "\n",
    "    upscaled_means = F.interpolate(src_noise, scale_factor=(up_factor, up_factor), mode='nearest')\n",
    "\n",
    "    up_H = up_factor * H\n",
    "    up_W = up_factor * W\n",
    "\n",
    "    \"\"\"\n",
    "        1) Unconditionally sample a discrete Nk x Nk Gaussian sample\n",
    "    \"\"\"\n",
    "\n",
    "    raw_rand = torch.randn(B, C, up_H, up_W)\n",
    "\n",
    "    \"\"\"\n",
    "        2) Remove its mean from it\n",
    "    \"\"\"\n",
    "\n",
    "    Z_mean = raw_rand.unfold(2, up_factor, up_factor).unfold(3, up_factor, up_factor).mean((4, 5))\n",
    "    Z_mean = F.interpolate(Z_mean, scale_factor=up_factor, mode='nearest')\n",
    "    mean_removed_rand = raw_rand - Z_mean\n",
    "\n",
    "    \"\"\"\n",
    "        3) Add the pixel value to it\n",
    "    \"\"\"\n",
    "\n",
    "    up_noise = upscaled_means / up_factor + mean_removed_rand\n",
    "\n",
    "    return up_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def gridy2x_pers2erp(gridy, HWy, HWx, THETA, PHI, FOVy, FOVx):\n",
    "    H, W, h, w = *HWy, *HWx\n",
    "    hFOVy, wFOVy = FOVy * float(H) / W, FOVy\n",
    "    hFOVx, wFOVx = FOVx * float(h) / w, FOVx\n",
    "    \n",
    "    # gridy2x\n",
    "    ### onto sphere\n",
    "    gridy = gridy.reshape(-1, 2).float()\n",
    "    gridy[:, 0] *= np.tan(np.radians(hFOVy / 2.0))\n",
    "    gridy[:, 1] *= np.tan(np.radians(wFOVy / 2.0))\n",
    "    gridy = gridy.double().flip(-1)\n",
    "    \n",
    "    x0 = torch.ones(gridy.shape[0], 1)\n",
    "    gridy = torch.cat((x0, gridy), dim=-1)\n",
    "    gridy /= torch.norm(gridy, p=2, dim=-1, keepdim=True)\n",
    "    \n",
    "    ### rotation\n",
    "    y_axis = np.array([0.0, 1.0, 0.0], np.float64)\n",
    "    z_axis = np.array([0.0, 0.0, 1.0], np.float64)\n",
    "    [R1, _] = cv2.Rodrigues(z_axis * np.radians(THETA))\n",
    "    [R2, _] = cv2.Rodrigues(np.dot(R1, y_axis) * np.radians(PHI))   \n",
    "    \n",
    "    gridy = torch.mm(torch.from_numpy(R1), gridy.permute(1, 0)).permute(1, 0)\n",
    "    gridy = torch.mm(torch.from_numpy(R2), gridy.permute(1, 0)).permute(1, 0)\n",
    "\n",
    "    ### sphere to gridx\n",
    "    lat = torch.arcsin(gridy[:, 2]) / np.pi * 2\n",
    "    lon = torch.atan2(gridy[:, 1] , gridy[:, 0]) / np.pi\n",
    "    gridx = torch.stack((lat, lon), dim=-1)\n",
    "\n",
    "    # masky\n",
    "    mask = torch.where(torch.abs(gridx) > 1, 0, 1)\n",
    "    mask = mask[:, 0] * mask[:, 1]\n",
    "\n",
    "    return gridx.float(), mask.float()\n",
    "\n",
    "def gridy2x_erp2pers(gridy, HWy, HWx, THETA, PHI, FOVy, FOVx):\n",
    "    H, W, h, w = *HWy, *HWx\n",
    "    hFOVy, wFOVy = FOVy * float(H) / W, FOVy\n",
    "    hFOVx, wFOVx = FOVx * float(h) / w, FOVx\n",
    "\n",
    "    # gridy2x\n",
    "    ### onto sphere\n",
    "    gridy = gridy.reshape(-1, 2).float()\n",
    "    lat = gridy[:, 0] * np.pi / 2\n",
    "    lon = gridy[:, 1] * np.pi\n",
    "\n",
    "    z0 = torch.sin(lat)\n",
    "    y0 = torch.cos(lat) * torch.sin(lon)\n",
    "    x0 = torch.cos(lat) * torch.cos(lon)\n",
    "    gridy = torch.stack((x0, y0, z0), dim=-1).double()\n",
    "\n",
    "    ### rotation\n",
    "    y_axis = np.array([0.0, 1.0, 0.0], np.float64)\n",
    "    z_axis = np.array([0.0, 0.0, 1.0], np.float64)\n",
    "    [R1, _] = cv2.Rodrigues(z_axis * np.radians(THETA))\n",
    "    [R2, _] = cv2.Rodrigues(np.dot(R1, y_axis) * np.radians(PHI))\n",
    "\n",
    "    R1_inv = torch.inverse(torch.from_numpy(R1))\n",
    "    R2_inv = torch.inverse(torch.from_numpy(R2))\n",
    "\n",
    "    gridy = torch.mm(R2_inv, gridy.permute(1, 0)).permute(1, 0)\n",
    "    gridy = torch.mm(R1_inv, gridy.permute(1, 0)).permute(1, 0)\n",
    "\n",
    "    ### sphere to gridx\n",
    "    z0 = gridy[:, 2] / gridy[:, 0]\n",
    "    y0 = gridy[:, 1] / gridy[:, 0]\n",
    "    gridx = torch.stack((z0, y0), dim=-1).float()\n",
    "\n",
    "    # masky\n",
    "    mask = torch.where(torch.abs(gridx) > 1, 0, 1)\n",
    "    mask = mask[:, 0] * mask[:, 1]\n",
    "    mask *= torch.where(gridy[:, 0] < 0, 0, 1)\n",
    "\n",
    "    return gridx.float(), mask.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  Defining source noise map\n",
    "\"\"\"\n",
    "# Noise config\n",
    "up_level = 3     # Upsampling level k\n",
    "batch_size = 1   # Batch size\n",
    "dim_channel = 3  # Channel dimension\n",
    "H, W = 64, 128   # Original H, W\n",
    "visualize_sz = (512, 1024)\n",
    "\n",
    "# Sample the source noise\n",
    "src_noise = torch.randn(batch_size, dim_channel, H, W)\n",
    "\n",
    "# Upscale to 512 x 1024 and visualize, just for visualization purposes\n",
    "view_test_noise = F.interpolate(src_noise, size=visualize_sz, mode='nearest')\n",
    "to_img(view_test_noise[0]).save(\"0_view_test_noise.png\")\n",
    "\n",
    "# Generate conditionally upsampled noise by k = up_level\n",
    "up_noise = cond_noise_sampling(src_noise, level=up_level)\n",
    "\n",
    "# Visualize upsampled noise\n",
    "test_upsampled_noise_vis = F.interpolate(up_noise, size=visualize_sz, mode='nearest')\n",
    "to_img(test_upsampled_noise_vis[0]).save(\"1_test_upsampled_noise_vis.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perspective-to-ERP 매핑을 위한 설정\n",
    "H_pers, W_pers = 64, 64  # Perspective view(tgt)의 해상도\n",
    "theta, phi = 0, 0        # View direction (THETA: yaw, PHI: pitch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  Defining the partitioned polygons for target noise map\n",
    "\"\"\"\n",
    "B, C, H, W = src_noise.shape\n",
    "\n",
    "\n",
    "# Defining a 2x upscaled, partitioned pixel map with vertex index numbers for rasterization\n",
    "tr_H_pers = H_pers * 2 + 1\n",
    "tr_W_pers = W_pers * 2 + 1\n",
    "\n",
    "i, j = torch.meshgrid(\n",
    "        torch.arange(tr_H_pers, dtype=torch.int32),\n",
    "        torch.arange(tr_W_pers, dtype=torch.int32),\n",
    "        indexing=\"ij\",\n",
    "    )\n",
    "\n",
    "mesh_idxs = torch.stack((i,j), dim=-1) # (tr_H_pers, tr_W_pers, 2)\n",
    "reshaped_mesh_idxs = mesh_idxs.reshape(-1,2)\n",
    "\n",
    "# per_tri_verts defining 8 polygonal partitions for a single original pixel\n",
    "front_tri_verts = torch.tensor([[0, 1, 1+tr_W_pers], [0, tr_W_pers, 1+tr_W_pers], [tr_W_pers, 1+tr_W_pers, 1+2*tr_W_pers], [tr_W_pers, 2*tr_W_pers, 1+2*tr_W_pers]])\n",
    "per_tri_verts = torch.cat((front_tri_verts, front_tri_verts + 1),dim=0)\n",
    "\n",
    "\n",
    "# Defining 'starting vertex indices' representing original pixels at 2x upscaled pixel map\n",
    "width = torch.arange(0, tr_W_pers - 1, 2)\n",
    "height = torch.arange(0, tr_H_pers-1, 2) * (tr_W_pers)\n",
    "# width_l = torch.linspace(0, tr_W_pers-2, tr_W-1)\n",
    "\n",
    "start_idxs = (width[None,...] + height[...,None]).reshape(-1,1)\n",
    "vertices = (start_idxs.repeat(1,8)[...,None] + per_tri_verts[None,...]).reshape(-1,3)\n",
    "num_faces = vertices.shape[0]\n",
    "\n",
    "# print(width)\n",
    "# print(height)\n",
    "# print(start_idxs.shape) # --> size == original resolution's pixel num == H x W if correct\n",
    "# print(vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  Defining target noise map coord. to source noise map\n",
    "\"\"\"\n",
    "\n",
    "# Perspective view grid 생성 (not pixel's center, but pixel border)\n",
    "pers_grid_y, pers_grid_x = torch.meshgrid(\n",
    "   torch.linspace(-1, 1, tr_H_pers),  # 수직 좌표 (normalized)\n",
    "   torch.linspace(-1, 1, tr_W_pers),  # 수평 좌표 (normalized)\n",
    "   indexing=\"ij\"\n",
    ")\n",
    "\n",
    "pers_grid = torch.stack((pers_grid_y, pers_grid_x), dim=-1)  # (tr_H_pers, tr_W_pers, 2)\n",
    "\n",
    "# Perspective-to-ERP 좌표 변환\n",
    "pers2erp_coords, _ = gridy2x_pers2erp(\n",
    "   gridy=pers_grid,\n",
    "   HWy=(2*H_pers, 2*W_pers),  # Perspective 해상도\n",
    "   HWx=(2*H, 2*W),            # ERP 해상도\n",
    "   THETA=theta, \n",
    "   PHI=phi, \n",
    "   FOVy=90,\n",
    "   FOVx=360\n",
    ")\n",
    "\n",
    "print(pers2erp_coords[..., 0].max(), pers2erp_coords[..., 0].min())\n",
    "print(pers2erp_coords[..., 1].max(), pers2erp_coords[..., 1].min())\n",
    "\n",
    "# Perspective-to-ERP 좌표를 ERP 해상도로 매핑\n",
    "pers2erp_coords[..., 0] = (pers2erp_coords[..., 0] + 1) / 2 * (2*H)\n",
    "pers2erp_coords[..., 1] = (pers2erp_coords[..., 1] + 1) / 2 * (2*W)\n",
    "\n",
    "tgt_to_src_map = pers2erp_coords.view(tr_H_pers, tr_W_pers, 2)\n",
    "\n",
    "print(pers2erp_coords[..., 0].max(), pers2erp_coords[..., 0].min())\n",
    "print(pers2erp_coords[..., 1].max(), pers2erp_coords[..., 1].min())\n",
    "print(\"tgt_to_src_map min/max:\", tgt_to_src_map.min(), tgt_to_src_map.max())\n",
    "print(\"vertices min/max:\", vertices.min(), vertices.max())\n",
    "print(\"vertices shape:\", vertices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Triangle rasterization using Nvdiffrast\n",
    "\"\"\"\n",
    "\n",
    "idx_y = reshaped_mesh_idxs[...,0].int()\n",
    "idx_x = reshaped_mesh_idxs[...,1].int()\n",
    "\n",
    "# Nvdiffrast input must be (x,y), so it must be flipped!!\n",
    "coords_len = idx_y.shape[0] # 16641\n",
    "warped_coords = tgt_to_src_map[idx_y, idx_x].fliplr()\n",
    "\n",
    "resolution= H * (2 ** up_level)\n",
    "device = \"cuda\"\n",
    "\n",
    "warped_coords = warped_coords.float()\n",
    "warped_coords[..., 0] = (warped_coords[..., 0] - W) / W\n",
    "warped_coords[..., 1] = (warped_coords[..., 1] - H) / H\n",
    "\n",
    "warped_vtx_pos = torch.cat((warped_coords, torch.zeros(coords_len, 1), torch.ones(coords_len, 1)), dim=-1)\n",
    "\n",
    "# To avoid ranged error\n",
    "warped_vtx_pos = warped_vtx_pos[None,...].to(device)\n",
    "vertices = vertices.int().to(device)\n",
    "\n",
    "print(warped_vtx_pos[..., 0].max(), warped_vtx_pos[..., 0].min())\n",
    "print(warped_vtx_pos[..., 1].max(), warped_vtx_pos[..., 1].min())\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    rast_out, _ = dr.rasterize(glctx, warped_vtx_pos, vertices, resolution=[resolution, 2*resolution])\n",
    "\n",
    "rast = rast_out[:,:,:,3:].permute(0,3,1,2).to(torch.int64) # 1, 1, 512, 1024\n",
    "\n",
    "# # Delete the context\n",
    "# del glctx\n",
    "\n",
    "# Rasterization visualization\n",
    "up_noise_vis = F.interpolate(rast.float(), size=visualize_sz, mode='nearest')\n",
    "\n",
    "plt.imsave(f'2_rast_{theta}_{phi}.png', rast[0, 0].cpu().numpy(), cmap='viridis')  # cmap은 필요하면 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  finding pixel indices in cond-upsampled map that belong to each polygon triangle,\n",
    "  and then adding them up\n",
    "\n",
    "  This implementation uses torch.scatter() to do this in parallel, so it is faster\n",
    "\"\"\"\n",
    "\n",
    "# Assign same index to triangles from the same original pixel, 0 if no index\n",
    "indices = (rast - 1) // 8 + 1 # there is 8 triangles per pixel\n",
    "\n",
    "# Flatten the upsampled noise\n",
    "up_noise_flat = up_noise.reshape(B*C, -1).cpu()\n",
    "\n",
    "# Create a flatten vector of ones for \"Cardinality\" value i.e. number of contained pixels\n",
    "ones_flat = torch.ones_like(up_noise_flat[:1])\n",
    "\n",
    "# Flatten the indices (and broadcast to batch size)\n",
    "indices_flat = indices.reshape(1, -1).cpu().to(torch.int64)\n",
    "\n",
    "# Aggregate the noise values and cardinality using scattering operation\n",
    "fin_v_val = torch.zeros(B*C, H_pers*W_pers+1).scatter_add_(1, index=indices_flat.repeat(B*C, 1), src=up_noise_flat)[..., 1:]\n",
    "fin_v_num = torch.zeros(1, H_pers*W_pers+1).scatter_add_(1, index=indices_flat, src=ones_flat)[..., 1:]\n",
    "\n",
    "assert fin_v_num.min() != 0\n",
    "\n",
    "print(fin_v_num.min(), fin_v_num.max())\n",
    "\n",
    "final_values = fin_v_val / torch.sqrt(fin_v_num)\n",
    "\n",
    "warped_noise_fast = final_values.reshape(B, C, H_pers, W_pers).float()\n",
    "\n",
    "up_vis_fast = F.interpolate(warped_noise_fast, size=(512, 512), mode='nearest')\n",
    "\n",
    "to_img(up_vis_fast[0]).save(f\"3_up_vis_fast_{theta}_{phi}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the tensor across all channels and batches\n",
    "flattened_noise = warped_noise_fast.flatten().numpy()\n",
    "\n",
    "# Plot the histogram of pixel values\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(flattened_noise, bins=100, density=True, alpha=0.6, color='blue', label='Pixel Values')\n",
    "\n",
    "# Overlay a Gaussian curve for comparison\n",
    "mean, std = 0, 1\n",
    "print(mean, std)\n",
    "x = np.linspace(-4.5, 4.5, 1000)\n",
    "gaussian_curve = (1 / (std * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x - mean) / std) ** 2)\n",
    "\n",
    "plt.plot(x, gaussian_curve, color='red', linestyle='--', label='Gaussian Fit')\n",
    "plt.title(\"Distribution of Pixel Values in warped_noise_fast\")\n",
    "plt.xlabel(\"Pixel Value\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.xticks(np.arange(-5, 6, 1))  # Customize x-axis grid\n",
    "plt.yticks(np.arange(0, 0.5, 0.05))  # Customize y-axis grid\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(f\"4_hist_{theta}_{phi}.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
