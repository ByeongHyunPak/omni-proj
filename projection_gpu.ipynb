{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def pil_to_tensor(pil_image):\n",
    "  transform = transforms.ToTensor()\n",
    "  tensor_image = transform(pil_image)\n",
    "  return tensor_image\n",
    "\n",
    "def tensor_to_pil(tensor_image):\n",
    "    transform = transforms.ToPILImage()\n",
    "    pil_image = transform(tensor_image)\n",
    "    return pil_image\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "  images = []\n",
    "  for filename in os.listdir(folder):\n",
    "    img_path = os.path.join(folder, filename)\n",
    "    if os.path.isfile(img_path) and img_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "      try:\n",
    "        img = Image.open(img_path)\n",
    "        images.append(img)\n",
    "      except Exception as e:\n",
    "        print(f\"Error loading image {img_path}: {e}\")\n",
    "  return images\n",
    "\n",
    "def draw_boundary_on_image(image_tensor, mask_tensor, boundary_color=(0, 0, 255), boundary_thickness=10):\n",
    "    if mask_tensor.dtype != torch.uint8:\n",
    "        mask_tensor = (mask_tensor * 255).to(torch.uint8)\n",
    "\n",
    "    if image_tensor.dtype != torch.uint8:\n",
    "        image_tensor = (image_tensor * 255).to(torch.uint8)\n",
    "\n",
    "    if len(mask_tensor.shape) == 3:\n",
    "        mask_tensor = mask_tensor[0, :, :]\n",
    "\n",
    "    mask_np = mask_tensor.numpy().astype(np.uint8)\n",
    "    contours, _ = cv2.findContours(mask_np, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    image_np = image_tensor.permute(1, 2, 0).numpy().copy()  # [C, H, W] -> [H, W, C]\n",
    "    cv2.drawContours(image_np, contours, -1, boundary_color, boundary_thickness)\n",
    "    output_image_tensor = torch.from_numpy(image_np).permute(2, 0, 1)  # 다시 [C, H, W]로 변경\n",
    "    \n",
    "    return output_image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ByeongHyunPak/omni-proj.git\n",
    "!pip install tensorboardX\n",
    "\n",
    "import os\n",
    "os.chdir('/content/omni-proj/omni_proj')\n",
    "\n",
    "imgs_folder = '/content/omni-proj/imgs/erps' \n",
    "images = load_images_from_folder(imgs_folder)\n",
    "\n",
    "for img in images:\n",
    "    img = pil_to_tensor(img)\n",
    "    print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def rodrigues_torch(rvec):\n",
    "    theta = torch.norm(rvec)\n",
    "    if theta < 1e-6:\n",
    "        return torch.eye(3, device=rvec.device)\n",
    "\n",
    "    rvec = rvec / theta\n",
    "    K = torch.tensor([[0, -rvec[2], rvec[1]],\n",
    "                      [rvec[2], 0, -rvec[0]],\n",
    "                      [-rvec[1], rvec[0], 0]], device=rvec.device)\n",
    "    R = torch.eye(3, device=rvec.device) + torch.sin(theta) * K + (1 - torch.cos(theta)) * torch.matmul(K, K)\n",
    "    return R  \n",
    "\n",
    "def gridy2x_per2erp_cuda(gridy, HWy, HWx, THETA, PHI, FOVy, FOVx, device='cuda'):\n",
    "    H, W, h, w = *HWy, *HWx\n",
    "    hFOVy, wFOVy = FOVy * float(H) / W, FOVy\n",
    "    hFOVx, wFOVx = FOVx * float(h) / w, FOVx\n",
    "\n",
    "    # gridy2x\n",
    "    ### onto sphere\n",
    "    gridy = gridy.reshape(-1, 2).float()\n",
    "    lat = gridy[:, 0] * np.pi / 2\n",
    "    lon = gridy[:, 1] * np.pi\n",
    "\n",
    "    z0 = torch.sin(lat)\n",
    "    y0 = torch.cos(lat) * torch.sin(lon)\n",
    "    x0 = torch.cos(lat) * torch.cos(lon)\n",
    "    gridy = torch.stack((x0, y0, z0), dim=-1).double()\n",
    "\n",
    "    ### rotation\n",
    "    y_axis = torch.tensor([0.0, 1.0, 0.0], device=device, dtype=torch.float64)\n",
    "    z_axis = torch.tensor([0.0, 0.0, 1.0], device=device, dtype=torch.float64)\n",
    "    R1 = rodrigues_torch(z_axis * np.radians(THETA))\n",
    "    R2 = rodrigues_torch(torch.matmul(R1, y_axis) * np.radians(PHI))\n",
    "\n",
    "    R1_inv = torch.inverse(R1)\n",
    "    R2_inv = torch.inverse(R2)\n",
    "\n",
    "    gridy = torch.mm(R2_inv, gridy.permute(1, 0)).permute(1, 0)\n",
    "    gridy = torch.mm(R1_inv, gridy.permute(1, 0)).permute(1, 0)\n",
    "\n",
    "    ### sphere to gridx\n",
    "    z0 = gridy[:, 2] / gridy[:, 0]\n",
    "    y0 = gridy[:, 1] / gridy[:, 0]\n",
    "    gridx = torch.stack((z0, y0), dim=-1).float()\n",
    "\n",
    "    # masky\n",
    "    mask = torch.where(torch.abs(gridx) > 1, 0, 1)\n",
    "    mask = mask[:, 0] * mask[:, 1]\n",
    "    mask *= torch.where(gridy[:, 0] < 0, 0, 1)\n",
    "\n",
    "    return gridx.to(torch.float32), mask.to(torch.float32)\n",
    "\n",
    "def gridy2x_erp2per_cuda(gridy, HWy, HWx, THETA, PHI, FOVy, FOVx, device='cuda'):\n",
    "    H, W, h, w = *HWy, *HWx\n",
    "    hFOVy, wFOVy = FOVy * float(H) / W, FOVy\n",
    "    hFOVx, wFOVx = FOVx * float(h) / w, FOVx\n",
    "    \n",
    "    # gridy2x\n",
    "    ### onto sphere\n",
    "    gridy = gridy.reshape(-1, 2).float()\n",
    "    gridy[:, 0] *= np.tan(np.radians(hFOVy / 2.0))\n",
    "    gridy[:, 1] *= np.tan(np.radians(wFOVy / 2.0))\n",
    "    gridy = gridy.double().flip(-1)\n",
    "    \n",
    "    x0 = torch.ones(gridy.shape[0], 1, device=device)\n",
    "    gridy = torch.cat((x0, gridy), dim=-1)\n",
    "    gridy /= torch.norm(gridy, p=2, dim=-1, keepdim=True)\n",
    "    \n",
    "    ### rotation\n",
    "    y_axis = torch.tensor([0.0, 1.0, 0.0], device=device, dtype=torch.float64)\n",
    "    z_axis = torch.tensor([0.0, 0.0, 1.0], device=device, dtype=torch.float64)\n",
    "    R1 = rodrigues_torch(z_axis * np.radians(THETA))\n",
    "    R2 = rodrigues_torch(torch.matmul(R1, y_axis) * np.radians(PHI))\n",
    "\n",
    "    gridy = torch.mm(R1, gridy.permute(1, 0)).permute(1, 0)\n",
    "    gridy = torch.mm(R2, gridy.permute(1, 0)).permute(1, 0)\n",
    "\n",
    "    ### sphere to gridx\n",
    "    lat = torch.arcsin(gridy[:, 2]) / np.pi * 2\n",
    "    lon = torch.atan2(gridy[:, 1] , gridy[:, 0]) / np.pi\n",
    "    gridx = torch.stack((lat, lon), dim=-1)\n",
    "\n",
    "    # masky\n",
    "    mask = torch.where(torch.abs(gridx) > 1, 0, 1)\n",
    "    mask = mask[:, 0] * mask[:, 1]\n",
    "\n",
    "    return gridx.to(torch.float32), mask.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "def erp2per_cuda(hr_erp_img, THETA, PHI, FOVy=90, FOVx=360, HWy=(512, 512), device='cuda'):\n",
    "    hr_erp_img = pil_to_tensor(hr_erp_img).to(device)\n",
    "    HWx = hr_erp_img.shape[-2:]\n",
    "\n",
    "    gridy = utils.make_coord(HWy).to(device)\n",
    "    gridy2x, masky = gridy2x_erp2per_cuda(\n",
    "        gridy, HWy, HWx, THETA, PHI, FOVy, FOVx, device)\n",
    "    gridy2x = gridy2x.view(*HWy, 2)\n",
    "\n",
    "    inp = F.grid_sample(hr_erp_img.unsqueeze(0),\n",
    "                        gridy2x.unsqueeze(0).flip(-1),\n",
    "                        mode='bicubic',\n",
    "                        padding_mode='reflection',\n",
    "                        align_corners=False).clamp_(0, 1)[0]\n",
    "\n",
    "    gridx = utils.make_coord(HWx, flatten=False).to(device)\n",
    "    gridx2y, maskx = gridy2x_per2erp_cuda(\n",
    "        gridx, HWx, HWy, THETA, PHI, FOVx, FOVy, device)\n",
    "    \n",
    "    maskx = maskx.view(1, *HWx)\n",
    "    valid_hr_erp_img = hr_erp_img * maskx\n",
    "    \n",
    "    return inp, valid_hr_erp_img, maskx\n",
    "\n",
    "def per2erp_cuda(hr_pers_img, THETA, PHI, FOVy=360, FOVx=90, HWy=(512, 1024), device='cuda'):\n",
    "    hr_pers_img = pil_to_tensor(hr_pers_img).to(device)\n",
    "    HWx = hr_pers_img.shape[-2:]\n",
    "\n",
    "    gridy = utils.make_coord(HWy).to(device)\n",
    "    gridy2x, masky = gridy2x_per2erp_cuda(\n",
    "        gridy, HWy, HWx, THETA, PHI, FOVy, FOVx, device)\n",
    "    gridy2x = gridy2x.view(*HWy, 2)\n",
    "    masky = masky.view(1, *HWy)\n",
    "\n",
    "    inp = F.grid_sample(hr_pers_img.unsqueeze(0),\n",
    "                        gridy2x.unsqueeze(0).flip(-1),\n",
    "                        mode='bicubic',\n",
    "                        padding_mode='reflection',\n",
    "                        align_corners=False).clamp_(0, 1)[0]\n",
    "    inp = inp * masky\n",
    "\n",
    "    gridx = utils.make_coord(HWx, flatten=False).to(device)\n",
    "    gridx2y, maskx = gridy2x_erp2per_cuda(\n",
    "        gridx, HWx, HWy, THETA, PHI, FOVx, FOVy, device)\n",
    "    \n",
    "    maskx = maskx.view(1, *HWx)\n",
    "    valid_hr_pers_img = hr_pers_img * maskx\n",
    "    \n",
    "    return inp, valid_hr_pers_img, maskx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "hr_erp_img = images[0]\n",
    "display(hr_erp_img)\n",
    "\n",
    "# ERP to Perspective\n",
    "THETA = random.uniform(-135, 135)\n",
    "PHI = random.uniform(-45, 45)\n",
    "\n",
    "pers_img, valid_hr_erp_img, _ = erp2per_cuda(hr_erp_img, THETA, PHI, FOVy=90, FOVx=360, device=device)\n",
    "\n",
    "display(tensor_to_pil(valid_hr_erp_img))\n",
    "display(tensor_to_pil(pers_img))\n",
    "\n",
    "# Pers to ERP\n",
    "erp_img, valid_lr_pers_img, _ = per2erp_cuda(tensor_to_pil(pers_img), THETA, PHI, FOVy=360, FOVx=90, device=device)\n",
    "\n",
    "display(tensor_to_pil(valid_lr_pers_img))\n",
    "display(tensor_to_pil(erp_img))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
